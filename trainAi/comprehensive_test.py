# Comprehensive model testing script
import pickle
import re
import pandas as pd

def preprocess_arabic_text(text):
    """Preprocess Arabic text consistently with training"""
    text = re.sub(r'[^\u0600-\u06FF\s]', '', text)  # Keep only Arabic characters and spaces
    text = re.sub(r'\s+', ' ', text).strip()  # Remove extra spaces

    # Remove common Arabic diacritics (tashkeel) if any
    arabic_diacritics = re.compile(r'[\u064B-\u0652\u0670\u0640]')
    text = arabic_diacritics.sub('', text)

    return text

def load_model():
    """Load the trained model and vectorizer"""
    print("Loading model...")
    with open('saved_model/classifier.pkl', 'rb') as f:
        model = pickle.load(f)

    with open('saved_model/vectorizer.pkl', 'rb') as f:
        vectorizer = pickle.load(f)

    print(f"Model loaded: {type(model).__name__}")
    print(f"Vectorizer loaded: {type(vectorizer).__name__}")
    return model, vectorizer

def predict_note(note, model, vectorizer):
    """Make prediction for a single note"""
    clean_note = preprocess_arabic_text(note)
    note_tfidf = vectorizer.transform([clean_note])
    prediction = model.predict(note_tfidf)[0]
    probabilities = model.predict_proba(note_tfidf)[0]
    confidence = max(probabilities)

    # Get probabilities for each class
    class_probs = dict(zip(model.classes_, probabilities))

    return {
        'prediction': prediction,
        'confidence': confidence,
        'probabilities': class_probs
    }

def run_comprehensive_tests():
    """Run comprehensive tests across all categories"""

    # Load model
    model, vectorizer = load_model()

    # Comprehensive test cases
    test_cases = {
        "LOW Priority (Excellent Performance)": [
            ("Ø§Ù„Ø·Ø§Ù„Ø¨Ø© Ù…ØªÙÙˆÙ‚Ø© ÙˆÙ…Ø´Ø§Ø±ÙƒØ© ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù†Ø´Ø·Ø©", "low"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨ Ù…ØªÙ…ÙŠØ² ÙÙŠ Ø§Ù„Ø¯Ø±Ø§Ø³Ø© ÙˆÙŠØ­Ø¨ Ø§Ù„ØªØ¹Ù„Ù…", "low"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨Ø© ØªØªÙÙˆÙ‚ Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ§Ù‹ ÙˆØªØ³Ø§Ø¹Ø¯ Ø²Ù…Ù„Ø§Ø¡Ù‡Ø§", "low"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨ Ù…Ù†Ø¸Ù… ÙˆÙ…ØªÙØ§Ø¹Ù„ Ù…Ø¹ Ø§Ù„Ù…Ø¹Ù„Ù…ÙŠÙ†", "low"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨Ø© Ù„Ø¯ÙŠÙ‡Ø§ Ù…Ù‡Ø§Ø±Ø§Øª Ù‚ÙŠØ§Ø¯ÙŠØ© Ø±Ø§Ø¦Ø¹Ø©", "low"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨ ÙŠØ´Ø§Ø±Ùƒ Ø¨Ø­Ù…Ø§Ø³ ÙÙŠ Ø§Ù„Ù†Ù‚Ø§Ø´Ø§Øª", "low"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨Ø© ØªØ¨Ø¯ÙŠ ÙÙ‡Ù…Ø§Ù‹ Ø¹Ù…ÙŠÙ‚Ø§Ù‹ Ù„Ù„Ù…ÙˆØ§Ø¯", "low"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨ Ù…Ù„ØªØ²Ù… Ø¨Ø§Ù„Ø­Ø¶ÙˆØ± ÙˆØ§Ù„ÙˆØ§Ø¬Ø¨Ø§Øª", "low"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨Ø© ØªØ¸Ù‡Ø± Ø¥Ø¨Ø¯Ø§Ø¹Ø§Ù‹ ÙÙŠ Ø­Ù„ Ø§Ù„Ù…Ø³Ø§Ø¦Ù„", "low"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨ Ù…ØªØ¹Ø§ÙˆÙ† ÙˆÙ…Ø­Ø¨ÙˆØ¨ Ù…Ù† Ø²Ù…Ù„Ø§Ø¦Ù‡", "low")
        ],

        "MODERATE Priority (Needs Support)": [
            ("Ø§Ù„Ø·Ø§Ù„Ø¨Ø© ØªØ­ØªØ§Ø¬ Ù…Ø³Ø§Ø¹Ø¯Ø© Ø¥Ø¶Ø§ÙÙŠØ© ÙÙŠ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª", "moderate"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨ ÙŠØ¨Ø°Ù„ Ø¬Ù‡Ø¯Ø§Ù‹ Ù„ÙƒÙ† ÙŠØ­ØªØ§Ø¬ ØªØ´Ø¬ÙŠØ¹Ø§Ù‹", "moderate"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨Ø© ØªØªØ±Ø¯Ø¯ ÙÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø£Ø­ÙŠØ§Ù†Ø§Ù‹", "moderate"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨ ÙŠØ­ØªØ§Ø¬ ÙˆÙ‚ØªØ§Ù‹ Ø£Ø·ÙˆÙ„ Ù„ÙÙ‡Ù… Ø§Ù„Ø¯Ø±ÙˆØ³", "moderate"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨Ø© ØªØ­ØªØ§Ø¬ ØªØ·ÙˆÙŠØ± Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„ÙƒØªØ§Ø¨Ø©", "moderate"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨ Ø£Ø­ÙŠØ§Ù†Ø§Ù‹ ÙŠØªØ´ØªØª Ù„ÙƒÙ†Ù‡ Ù…Ø¬ØªÙ‡Ø¯", "moderate"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨Ø© ØªØ­ØªØ§Ø¬ Ø¯Ø¹Ù…Ø§Ù‹ ÙÙŠ Ø§Ù„Ø«Ù‚Ø© Ø¨Ø§Ù„Ù†ÙØ³", "moderate"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨ ÙŠØ­ØªØ§Ø¬ Ù…ØªØ§Ø¨Ø¹Ø© ÙÙŠ Ø£Ø¯Ø§Ø¡ Ø§Ù„ÙˆØ§Ø¬Ø¨Ø§Øª", "moderate"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨Ø© ØªØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ† Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„ØªÙ†Ø¸ÙŠÙ…", "moderate"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨ ÙŠØ­ØªØ§Ø¬ Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ÙˆÙ‚Øª", "moderate")
        ],

        "HIGH Priority (Serious Concerns)": [
            ("Ø§Ù„Ø·Ø§Ù„Ø¨Ø© ØªØ¹Ø§Ù†ÙŠ Ù…Ù† ØµØ¹ÙˆØ¨Ø§Øª ÙƒØ¨ÙŠØ±Ø© ÙÙŠ Ø§Ù„ØªØ¹Ù„Ù…", "high"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨ ØºØ§Ø¨ ÙƒØ«ÙŠØ±Ø§Ù‹ ÙˆÙ„Ù… ÙŠØ³Ù„Ù… Ø§Ù„ÙˆØ§Ø¬Ø¨Ø§Øª", "high"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨Ø© ØªÙˆØ§Ø¬Ù‡ Ù…Ø´Ø§ÙƒÙ„ Ø³Ù„ÙˆÙƒÙŠØ© Ø®Ø·ÙŠØ±Ø©", "high"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨ ÙŠØ¹Ø§Ù†ÙŠ Ù…Ù† Ù‚Ù„Ù‚ Ø´Ø¯ÙŠØ¯ ÙŠØ¤Ø«Ø± Ø¹Ù„Ù‰ Ø¯Ø±Ø§Ø³ØªÙ‡", "high"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨Ø© Ù„Ø§ ØªØ³ØªØ·ÙŠØ¹ Ø§Ù„ØªØ±ÙƒÙŠØ² Ù†Ù‡Ø§Ø¦ÙŠØ§Ù‹", "high"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨ ÙŠØ¹Ø§Ù†ÙŠ Ù…Ù† Ø¥Ø­Ø¨Ø§Ø· Ø´Ø¯ÙŠØ¯ ÙˆÙŠØ±ÙØ¶ Ø§Ù„Ù…Ø´Ø§Ø±ÙƒØ©", "high"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨Ø© ØªØªØ¹Ø±Ø¶ Ù„Ù†ÙˆØ¨Ø§Øª Ù‚Ù„Ù‚ ØªÙ…Ù†Ø¹Ù‡Ø§ Ù…Ù† Ø§Ù„Ù…Ø´Ø§Ø±ÙƒØ©", "high"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨ Ù„Ø¯ÙŠÙ‡ ØµØ¹ÙˆØ¨Ø§Øª Ø¬Ø³ÙŠÙ…Ø© ÙÙŠ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© ÙˆØ§Ù„ÙƒØªØ§Ø¨Ø©", "high"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨Ø© Ù…Ù†Ø¹Ø²Ù„Ø© ØªÙ…Ø§Ù…Ø§Ù‹ Ø¹Ù† Ø²Ù…Ù„Ø§Ø¦Ù‡Ø§", "high"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨ ÙŠØ¸Ù‡Ø± Ø¹Ù„Ø§Ù…Ø§Øª Ø§ÙƒØªØ¦Ø§Ø¨ ÙˆØ§Ø¶Ø­Ø©", "high")
        ],

        "Edge Cases (Tricky Examples)": [
            ("Ø§Ù„Ø·Ø§Ù„Ø¨Ø© Ù…Ø´Ø§Ø±ÙƒØ© Ù„ÙƒÙ† ØªØ­ØªØ§Ø¬ ØªØ´Ø¬ÙŠØ¹Ø§Ù‹", "moderate"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨ Ù…ØªÙÙˆÙ‚ Ù„ÙƒÙ† Ø®Ø¬ÙˆÙ„ Ø¬Ø¯Ø§Ù‹", "moderate"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨Ø© ØªØ­Ø¨ Ø§Ù„Ù…Ø§Ø¯Ø© Ù„ÙƒÙ† ØªØ¬Ø¯ ØµØ¹ÙˆØ¨Ø© ÙÙŠÙ‡Ø§", "moderate"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨ Ø°ÙƒÙŠ Ù„ÙƒÙ† ÙƒØ³ÙˆÙ„ ÙÙŠ Ø£Ø¯Ø§Ø¡ Ø§Ù„ÙˆØ§Ø¬Ø¨Ø§Øª", "moderate"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨Ø© Ù…ØªÙØ§Ø¹Ù„Ø© Ù„ÙƒÙ† ØªÙ†Ø³Ù‰ Ø§Ù„ÙˆØ§Ø¬Ø¨Ø§Øª Ø£Ø­ÙŠØ§Ù†Ø§Ù‹", "moderate"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨ Ù…ÙˆÙ‡ÙˆØ¨ Ù„ÙƒÙ† Ù„Ø§ ÙŠØ«Ù‚ Ø¨Ù†ÙØ³Ù‡", "moderate"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨Ø© Ù†Ø´Ø·Ø© Ù„ÙƒÙ† ØªØªØ´ØªØª Ø¨Ø³Ø±Ø¹Ø©", "moderate"),
            ("Ø§Ù„Ø·Ø§Ù„Ø¨ ÙŠØ´Ø§Ø±Ùƒ Ù„ÙƒÙ† ÙŠØ­ØªØ§Ø¬ ØªÙ†Ø¸ÙŠÙ…Ø§Ù‹ Ø£ÙƒØ«Ø±", "moderate")
        ]
    }

    print("\n" + "="*80)
    print("ğŸ§ª COMPREHENSIVE MODEL TESTING")
    print("="*80)

    total_correct = 0
    total_tests = 0
    category_results = {}

    for category, cases in test_cases.items():
        print(f"\nğŸ“‹ {category}")
        print("-" * 60)

        correct_in_category = 0

        for i, (note, expected) in enumerate(cases, 1):
            result = predict_note(note, model, vectorizer)
            predicted = result['prediction']
            confidence = result['confidence']
            probs = result['probabilities']

            is_correct = predicted == expected
            if is_correct:
                correct_in_category += 1
                total_correct += 1
                status = "âœ…"
            else:
                status = "âŒ"

            total_tests += 1

            print(f"{status} {i:2d}. {note}")
            print(f"     Expected: {expected.upper():8} | Predicted: {predicted.upper():8} | Confidence: {confidence:.3f}")
            print(f"     Probabilities: H:{probs.get('high', 0):.3f} M:{probs.get('moderate', 0):.3f} L:{probs.get('low', 0):.3f}")
            print()

        category_accuracy = correct_in_category / len(cases)
        category_results[category] = {
            'correct': correct_in_category,
            'total': len(cases),
            'accuracy': category_accuracy
        }

        print(f"ğŸ“Š Category Accuracy: {category_accuracy:.1%} ({correct_in_category}/{len(cases)})")

    # Overall results
    overall_accuracy = total_correct / total_tests

    print("\n" + "="*80)
    print("ğŸ“ˆ OVERALL TEST RESULTS")
    print("="*80)

    for category, results in category_results.items():
        acc = results['accuracy']
        color = "ğŸŸ¢" if acc >= 0.8 else "ğŸŸ¡" if acc >= 0.6 else "ğŸ”´"
        print(f"{color} {category:<35}: {acc:>6.1%} ({results['correct']}/{results['total']})")

    print(f"\nğŸ¯ OVERALL ACCURACY: {overall_accuracy:.1%} ({total_correct}/{total_tests})")

    # Performance analysis
    print("\n" + "="*80)
    print("ğŸ” PERFORMANCE ANALYSIS")
    print("="*80)

    if overall_accuracy >= 0.85:
        print("ğŸŸ¢ EXCELLENT: Model performs very well across all categories!")
    elif overall_accuracy >= 0.75:
        print("ğŸŸ¡ GOOD: Model performs well but has room for improvement.")
    elif overall_accuracy >= 0.65:
        print("ğŸŸ  FAIR: Model has decent performance but needs refinement.")
    else:
        print("ğŸ”´ POOR: Model needs significant improvement.")

    # Specific recommendations
    print("\nğŸ“ RECOMMENDATIONS:")

    low_acc = category_results["LOW Priority (Excellent Performance)"]['accuracy']
    mod_acc = category_results["MODERATE Priority (Needs Support)"]['accuracy']
    high_acc = category_results["HIGH Priority (Serious Concerns)"]['accuracy']
    edge_acc = category_results["Edge Cases (Tricky Examples)"]['accuracy']

    if low_acc < 0.8:
        print("- âš ï¸  Improve recognition of excellent student performance")
    if mod_acc < 0.8:
        print("- âš ï¸  Better distinguish moderate support needs")
    if high_acc < 0.8:
        print("- âš ï¸  More training needed for serious concern detection")
    if edge_acc < 0.7:
        print("- âš ï¸  Edge cases need more nuanced training data")

    if overall_accuracy >= 0.8:
        print("- âœ… Model is ready for production use!")
    else:
        print("- ğŸ“š Consider adding more training data")
        print("- ğŸ”§ Fine-tune model parameters")
        print("- ğŸ“– Review misclassified cases for patterns")

    print("\n" + "="*80)
    print("ğŸ TESTING COMPLETED")
    print("="*80)

if __name__ == "__main__":
    run_comprehensive_tests()
