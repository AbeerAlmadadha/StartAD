# source .venv/bin/activate
# streamlit run app.py


import streamlit as st
from final import generate_ai_suggestions

# Page config
st.set_page_config(page_title="Ø£Ø¯Ø§Ø© Ø¯Ø¹Ù… Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø± Ù„Ù„Ù…Ø¹Ù„Ù…ÙŠÙ†", layout="wide")

# Header
st.markdown(
    """
    <div style="text-align:center; padding:20px; background-color:#2c5282; border-radius:12px;">
        <h1 style="color:white; margin-bottom:5px;">ğŸ« Ø£Ø¯Ø§Ø© Ø¯Ø¹Ù… Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø± Ù„Ù„Ù…Ø¹Ù„Ù…ÙŠÙ†</h1>
        <p style="color:white; font-size:16px;">Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ù„Ù…ÙŠÙ† ÙÙŠ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø·Ù„Ø§Ø¨ ÙˆØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ø¯Ø¹Ù… ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨</p>
    </div>
    """,
    unsafe_allow_html=True
)

st.write("")

# Input section in two columns
col1, col2 = st.columns([1, 2])

with col1:
    st.markdown("### ğŸ†” Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø·Ø§Ù„Ø¨")
    student_id = st.text_input("Ø±Ù‚Ù… Ø§Ù„Ø·Ø§Ù„Ø¨:")

with col2:
    st.markdown("### âœï¸ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„Ù…Ø¹Ù„Ù…")
    prompt = st.text_area("Ø£Ø¯Ø®Ù„ Ù…Ù„Ø§Ø­Ø¸Ø§ØªÙƒ Ù‡Ù†Ø§:", height=180)

st.write("")

# Submit button
submit = st.button("Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", key="submit")

# AI Response area
if submit:
    if not student_id or not prompt:
        st.warning("âš ï¸ ÙŠØ±Ø¬Ù‰ Ù…Ù„Ø¡ Ø±Ù‚Ù… Ø§Ù„Ø·Ø§Ù„Ø¨ ÙˆØ§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„.")
    else:
        with st.spinner("Ø¬Ø§Ø±Ù ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø© ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª..."):
            try:
                result = generate_ai_suggestions(student_id, prompt)
            except Exception as e:
                st.error("Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ù‹Ø§.")
                st.exception(e)
                result = None

        if result:
            st.balloons()
            # AI response card
            with st.container():
                st.markdown(
                    f"""
                    <div style="
                        background-color:#f0f4f8;
                        padding:25px;
                        border-radius:12px;
                        border-left:5px solid #2c5282;
                        box-shadow: 2px 2px 12px rgba(0,0,0,0.1);
                        color: #000000;
                    ">
                        <h3 style="color:#2c5282;">ğŸ¤– Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ù„Ø·Ø§Ù„Ø¨ Ø±Ù‚Ù…: {result.get('student_id','')}</h3>
                        <p><strong>Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø®Ø·ÙˆØ±Ø©:</strong> {result.get('risk_level','-')}</p>
                        <p><strong>Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡:</strong> {result.get('recommended_action','-')}</p>
                        <details>
                            <summary>Ø¹Ø±Ø¶ Ø§Ù„ØªÙØ§ØµÙŠÙ„</summary>
                            <div style="margin-top:10px;">
                                <p><strong>Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨/Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª:</strong></p>
                                <ul>
                                    {''.join(f'<li>{item}</li>' for item in result.get('rationale', []))}
                                </ul>
                                <p><strong>Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª ÙÙˆØ±ÙŠØ©:</strong></p>
                                <ul>
                                    {''.join(f'<li>{item}</li>' for item in result.get('immediate_actions', []))}
                                </ul>
                                <p><strong>Ù…ØªØ§Ø¨Ø¹Ø© Ù„Ø§Ø­Ù‚Ø©:</strong></p>
                                <ul>
                                    {''.join(f'<li>{item}</li>' for item in result.get('follow_up', []))}
                                </ul>
                            </div>
                        </details>
                    </div>
                    """,
                    unsafe_allow_html=True
                )








# import streamlit as st
# from langchain.prompts import PromptTemplate
# from langchain.chains import LLMChain
# from langchain_openai import ChatOpenAI  # âœ… New import

# st.title("Staff Decision-Support Tool")
# st.divider()
# st.write("""Enter your observations or concerns about a student.
#          The AI will suggest possible referral pathways to NCMH and ways to support the student.""")

# prompt = st.text_input("Your prompt:")
# st.divider()

# if prompt:
#     st.balloons()

    # # âœ… Use ChatOpenAI instead of old OpenAI
    # llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.3)

    # # Prompt template
    # template = """You are an assistant helping teachers identify wellness issues.
    # Given a teacher's observation about a student, suggest:
    # 1. Possible referral pathways to the National Center for Mental Health (NCMH).
    # 2. Supportive actions the teacher/school can take immediately.
    # Keep responses clear, empathetic, and professional.

    # Teacher's note: {user_prompt}"""

    # prompt_template = PromptTemplate(input_variables=["user_prompt"], template=template)

    # # Build chain
    # llm_chain = LLMChain(prompt=prompt_template, llm=llm)

    # # Run chain with teacherâ€™s prompt
    # response = llm_chain.run(prompt)

    # st.subheader("Assistant Response:")
    # st.write(response)
